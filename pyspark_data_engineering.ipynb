{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f87d0b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cc6e05",
   "metadata": {},
   "source": [
    "## Import data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c1a0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Years_Experience</th>\n",
       "      <th>Height</th>\n",
       "      <th>Location_City</th>\n",
       "      <th>Sallary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emma</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>148190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noah</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>New York</td>\n",
       "      <td>225073.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Olivia</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>115666.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liam</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.58</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>103567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ava</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.96</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>149350.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name   Age  Years_Experience  Height  Location_City   Sallary\n",
       "0    Emma  47.0               4.0    1.68        Chicago  148190.0\n",
       "1    Noah  73.0               1.0    1.55       New York  225073.0\n",
       "2  Olivia  32.0               1.0    1.66    Los Angeles  115666.0\n",
       "3    Liam  75.0              10.0    1.58  San Francisco  103567.0\n",
       "4     Ava   9.0               1.0    1.96        Chicago  149350.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd = pd.read_csv('age_data.csv')\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5536d2f",
   "metadata": {},
   "source": [
    "## Import data with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9305354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e0dfb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/07 09:29:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "#Create Spark Session Locally. When working in the cloud you can create multiple clusters\n",
    "spark=SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7458d111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://us-hf-erik.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd669433a90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e849021a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Spark can read many options including csv, json, parquet\n",
    "df_pyspark = spark.read.csv('age_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0904d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------------+------+-------------+-------+\n",
      "|      _c0| _c1|             _c2|   _c3|          _c4|    _c5|\n",
      "+---------+----+----------------+------+-------------+-------+\n",
      "|     Name| Age|Years_Experience|Height|Location_City|Sallary|\n",
      "|     Emma|  47|               4|  1.68|      Chicago| 148190|\n",
      "|     Noah|  73|               1|  1.55|     New York| 225073|\n",
      "|   Olivia|  32|               1|  1.66|  Los Angeles| 115666|\n",
      "|     Liam|  75|              10|  1.58|San Francisco| 103567|\n",
      "|      Ava|   9|               1|  1.96|      Chicago| 149350|\n",
      "| Isabella|  78|              10|  1.79|     New York| 109479|\n",
      "|   Sophia|  80|               7|  1.95|  Los Angeles|  97866|\n",
      "|      Mia|  62|            null|  1.79|San Francisco| 154475|\n",
      "|Charlotte|  61|              10|  1.73|      Chicago| 199876|\n",
      "|   Amelia|  58|               2|  1.60|     New York| 214669|\n",
      "|   Harper|  74|               1|  1.79|  Los Angeles| 179705|\n",
      "|   Evelyn|  53|               6|  1.97|San Francisco| 171232|\n",
      "|  Abigail|  38|               2|  1.59|      Chicago|   null|\n",
      "|    Emily|  20|               9|  1.89|     New York| 144910|\n",
      "|Elizabeth|  22|              10|  1.69|  Los Angeles| 224057|\n",
      "|     Mila|  78|              10|  1.64|San Francisco| 139386|\n",
      "|     Ella|  29|               5|  1.95|      Chicago| 160033|\n",
      "|    Avery|null|              10|  1.97|     New York|  94983|\n",
      "|    Sofia|  56|               7|  2.02|  Los Angeles| 124729|\n",
      "|   Camila|  66|               4|  1.98|San Francisco| 188518|\n",
      "|     Aria|  78|               4|  1.79|      Chicago| 217043|\n",
      "| Scarlett|  67|               8|  2.00|     New York| 194911|\n",
      "| Victoria|  67|               1|  1.85|  Los Angeles|  92620|\n",
      "|  Madison|  23|               3|  1.87|San Francisco| 195767|\n",
      "|     Luna|  37|               6|  1.55|      Chicago| 216338|\n",
      "|    Grace|  22|               8|  1.80|     New York| 212176|\n",
      "|    Chloe|  22|            null|  1.92|  Los Angeles| 146957|\n",
      "| Penelope|  58|               9|  1.72|San Francisco| 168719|\n",
      "|    Layla|  36|               9|  2.01|      Chicago| 141444|\n",
      "|    Riley|  60|               3|  2.00|     New York| 215036|\n",
      "|     Zoey|  79|               1|  1.59|  Los Angeles|  80860|\n",
      "|     Nora|  61|               2|  1.82|San Francisco| 108105|\n",
      "|     Lily|  35|               3|  1.90|      Chicago|   null|\n",
      "|  Eleanor|  37|               9|  1.79|     New York| 139093|\n",
      "|   Hannah|  56|               2|  1.56|  Los Angeles| 222320|\n",
      "|  Lillian|  73|               3|  1.61|San Francisco| 161724|\n",
      "|  Addison|  13|               6|  2.02|      Chicago| 174984|\n",
      "|   Aubrey|  52|               1|  2.01|     New York| 215938|\n",
      "|    Ellie|  29|               5|  1.63|  Los Angeles| 120808|\n",
      "|   Stella|  26|               9|  1.62|San Francisco| 123158|\n",
      "|  Natalie|  14|               7|  1.92|      Chicago| 218458|\n",
      "|      Zoe|  65|              10|  1.68|     New York| 212527|\n",
      "|     Leah|null|               7|  1.84|  Los Angeles| 159327|\n",
      "|    Hazel|  34|               4|  1.62|San Francisco| 131026|\n",
      "|   Violet|  58|               3|  1.55|      Chicago| 102573|\n",
      "|   Aurora|  66|              10|  1.55|     New York| 197903|\n",
      "| Savannah|  49|            null|  1.93|  Los Angeles| 216618|\n",
      "|   Audrey|  35|               2|  1.99|San Francisco| 206294|\n",
      "| Brooklyn|  45|               7|  1.55|      Chicago| 109875|\n",
      "+---------+----+----------------+------+-------------+-------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b669f095",
   "metadata": {},
   "source": [
    "Let's get rid of _c0 and _c1 headers. Try using the option method when importing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d6811a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------------+------+-------------+-------+\n",
      "|     Name| Age|Years_Experience|Height|Location_City|Sallary|\n",
      "+---------+----+----------------+------+-------------+-------+\n",
      "|     Emma|  47|               4|  1.68|      Chicago| 148190|\n",
      "|     Noah|  73|               1|  1.55|     New York| 225073|\n",
      "|   Olivia|  32|               1|  1.66|  Los Angeles| 115666|\n",
      "|     Liam|  75|              10|  1.58|San Francisco| 103567|\n",
      "|      Ava|   9|               1|  1.96|      Chicago| 149350|\n",
      "| Isabella|  78|              10|  1.79|     New York| 109479|\n",
      "|   Sophia|  80|               7|  1.95|  Los Angeles|  97866|\n",
      "|      Mia|  62|            null|  1.79|San Francisco| 154475|\n",
      "|Charlotte|  61|              10|  1.73|      Chicago| 199876|\n",
      "|   Amelia|  58|               2|   1.6|     New York| 214669|\n",
      "|   Harper|  74|               1|  1.79|  Los Angeles| 179705|\n",
      "|   Evelyn|  53|               6|  1.97|San Francisco| 171232|\n",
      "|  Abigail|  38|               2|  1.59|      Chicago|   null|\n",
      "|    Emily|  20|               9|  1.89|     New York| 144910|\n",
      "|Elizabeth|  22|              10|  1.69|  Los Angeles| 224057|\n",
      "|     Mila|  78|              10|  1.64|San Francisco| 139386|\n",
      "|     Ella|  29|               5|  1.95|      Chicago| 160033|\n",
      "|    Avery|null|              10|  1.97|     New York|  94983|\n",
      "|    Sofia|  56|               7|  2.02|  Los Angeles| 124729|\n",
      "|   Camila|  66|               4|  1.98|San Francisco| 188518|\n",
      "|     Aria|  78|               4|  1.79|      Chicago| 217043|\n",
      "| Scarlett|  67|               8|   2.0|     New York| 194911|\n",
      "| Victoria|  67|               1|  1.85|  Los Angeles|  92620|\n",
      "|  Madison|  23|               3|  1.87|San Francisco| 195767|\n",
      "|     Luna|  37|               6|  1.55|      Chicago| 216338|\n",
      "|    Grace|  22|               8|   1.8|     New York| 212176|\n",
      "|    Chloe|  22|            null|  1.92|  Los Angeles| 146957|\n",
      "| Penelope|  58|               9|  1.72|San Francisco| 168719|\n",
      "|    Layla|  36|               9|  2.01|      Chicago| 141444|\n",
      "|    Riley|  60|               3|   2.0|     New York| 215036|\n",
      "|     Zoey|  79|               1|  1.59|  Los Angeles|  80860|\n",
      "|     Nora|  61|               2|  1.82|San Francisco| 108105|\n",
      "|     Lily|  35|               3|   1.9|      Chicago|   null|\n",
      "|  Eleanor|  37|               9|  1.79|     New York| 139093|\n",
      "|   Hannah|  56|               2|  1.56|  Los Angeles| 222320|\n",
      "|  Lillian|  73|               3|  1.61|San Francisco| 161724|\n",
      "|  Addison|  13|               6|  2.02|      Chicago| 174984|\n",
      "|   Aubrey|  52|               1|  2.01|     New York| 215938|\n",
      "|    Ellie|  29|               5|  1.63|  Los Angeles| 120808|\n",
      "|   Stella|  26|               9|  1.62|San Francisco| 123158|\n",
      "|  Natalie|  14|               7|  1.92|      Chicago| 218458|\n",
      "|      Zoe|  65|              10|  1.68|     New York| 212527|\n",
      "|     Leah|null|               7|  1.84|  Los Angeles| 159327|\n",
      "|    Hazel|  34|               4|  1.62|San Francisco| 131026|\n",
      "|   Violet|  58|               3|  1.55|      Chicago| 102573|\n",
      "|   Aurora|  66|              10|  1.55|     New York| 197903|\n",
      "| Savannah|  49|            null|  1.93|  Los Angeles| 216618|\n",
      "|   Audrey|  35|               2|  1.99|San Francisco| 206294|\n",
      "| Brooklyn|  45|               7|  1.55|      Chicago| 109875|\n",
      "|    Bella|  79|               7|  1.63|     New York|  78133|\n",
      "+---------+----+----------------+------+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.option('header', 'true').csv('age_data.csv', inferSchema=True)\n",
    "df_pyspark.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161dbe33",
   "metadata": {},
   "source": [
    "Let's look at the data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94d14e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566da8c9",
   "metadata": {},
   "source": [
    "it's a pyspark dataframe. However, many of the same pandas methods still work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23f4700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Emma', Age=47, Years_Experience=4, Height=1.68, Location_City='Chicago', Sallary=148190),\n",
       " Row(Name='Noah', Age=73, Years_Experience=1, Height=1.55, Location_City='New York', Sallary=225073),\n",
       " Row(Name='Olivia', Age=32, Years_Experience=1, Height=1.66, Location_City='Los Angeles', Sallary=115666),\n",
       " Row(Name='Liam', Age=75, Years_Experience=10, Height=1.58, Location_City='San Francisco', Sallary=103567),\n",
       " Row(Name='Ava', Age=9, Years_Experience=1, Height=1.96, Location_City='Chicago', Sallary=149350)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prints 5 rows in a list, it's better to use show method\n",
    "df_pyspark.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65ad3d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------------+------+-------------+-------+\n",
      "|     Name| Age|Years_Experience|Height|Location_City|Sallary|\n",
      "+---------+----+----------------+------+-------------+-------+\n",
      "|     Emma|  47|               4|  1.68|      Chicago| 148190|\n",
      "|     Noah|  73|               1|  1.55|     New York| 225073|\n",
      "|   Olivia|  32|               1|  1.66|  Los Angeles| 115666|\n",
      "|     Liam|  75|              10|  1.58|San Francisco| 103567|\n",
      "|      Ava|   9|               1|  1.96|      Chicago| 149350|\n",
      "| Isabella|  78|              10|  1.79|     New York| 109479|\n",
      "|   Sophia|  80|               7|  1.95|  Los Angeles|  97866|\n",
      "|      Mia|  62|            null|  1.79|San Francisco| 154475|\n",
      "|Charlotte|  61|              10|  1.73|      Chicago| 199876|\n",
      "|   Amelia|  58|               2|   1.6|     New York| 214669|\n",
      "|   Harper|  74|               1|  1.79|  Los Angeles| 179705|\n",
      "|   Evelyn|  53|               6|  1.97|San Francisco| 171232|\n",
      "|  Abigail|  38|               2|  1.59|      Chicago|   null|\n",
      "|    Emily|  20|               9|  1.89|     New York| 144910|\n",
      "|Elizabeth|  22|              10|  1.69|  Los Angeles| 224057|\n",
      "|     Mila|  78|              10|  1.64|San Francisco| 139386|\n",
      "|     Ella|  29|               5|  1.95|      Chicago| 160033|\n",
      "|    Avery|null|              10|  1.97|     New York|  94983|\n",
      "|    Sofia|  56|               7|  2.02|  Los Angeles| 124729|\n",
      "|   Camila|  66|               4|  1.98|San Francisco| 188518|\n",
      "+---------+----+----------------+------+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc009849",
   "metadata": {},
   "source": [
    ".printSchema() is the same as the .info() panadas method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67f06dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Years_Experience: integer (nullable = true)\n",
      " |-- Height: double (nullable = true)\n",
      " |-- Location_City: string (nullable = true)\n",
      " |-- Sallary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbf0f8b",
   "metadata": {},
   "source": [
    "### select certain columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "203de54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Years_Experience', 'Height', 'Location_City', 'Sallary']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get column names\n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "862e3e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     Name|\n",
      "+---------+\n",
      "|     Emma|\n",
      "|     Noah|\n",
      "|   Olivia|\n",
      "|     Liam|\n",
      "|      Ava|\n",
      "| Isabella|\n",
      "|   Sophia|\n",
      "|      Mia|\n",
      "|Charlotte|\n",
      "|   Amelia|\n",
      "|   Harper|\n",
      "|   Evelyn|\n",
      "|  Abigail|\n",
      "|    Emily|\n",
      "|Elizabeth|\n",
      "|     Mila|\n",
      "|     Ella|\n",
      "|    Avery|\n",
      "|    Sofia|\n",
      "|   Camila|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Look at individual column\n",
    "df_pyspark.select('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70e7797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4656b4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|     Name|Height|\n",
      "+---------+------+\n",
      "|     Emma|  1.68|\n",
      "|     Noah|  1.55|\n",
      "|   Olivia|  1.66|\n",
      "|     Liam|  1.58|\n",
      "|      Ava|  1.96|\n",
      "| Isabella|  1.79|\n",
      "|   Sophia|  1.95|\n",
      "|      Mia|  1.79|\n",
      "|Charlotte|  1.73|\n",
      "|   Amelia|   1.6|\n",
      "|   Harper|  1.79|\n",
      "|   Evelyn|  1.97|\n",
      "|  Abigail|  1.59|\n",
      "|    Emily|  1.89|\n",
      "|Elizabeth|  1.69|\n",
      "|     Mila|  1.64|\n",
      "|     Ella|  1.95|\n",
      "|    Avery|  1.97|\n",
      "|    Sofia|  2.02|\n",
      "|   Camila|  1.98|\n",
      "+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['Name', 'Height']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f3560e",
   "metadata": {},
   "source": [
    "### Check Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03a5aae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'),\n",
       " ('Age', 'int'),\n",
       " ('Years_Experience', 'int'),\n",
       " ('Height', 'double'),\n",
       " ('Location_City', 'string'),\n",
       " ('Sallary', 'int')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a11d930",
   "metadata": {},
   "source": [
    "Use the describe funtion to get statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb379076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+-----------------+------------------+-------------+------------------+\n",
      "|summary|   Name|               Age| Years_Experience|            Height|Location_City|           Sallary|\n",
      "+-------+-------+------------------+-----------------+------------------+-------------+------------------+\n",
      "|  count|     50|                48|               47|                50|           50|                48|\n",
      "|   mean|   null|49.729166666666664| 5.51063829787234|1.7819999999999998|         null|160968.72916666666|\n",
      "| stddev|   null| 21.03466195464285|3.276214281530039|0.1642670796884992|         null|45620.747785871616|\n",
      "|    min|Abigail|                 9|                1|              1.55|      Chicago|             78133|\n",
      "|    max|   Zoey|                80|               10|              2.02|San Francisco|            225073|\n",
      "+-------+-------+------------------+-----------------+------------------+-------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e43b3fb",
   "metadata": {},
   "source": [
    "### Add & Drop & Rename Columns in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01cc6dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add extra column called 'experience after 2 years'\n",
    "df_pyspark = df_pyspark.withColumn('Experience_after_2_years', df_pyspark['Years_Experience']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db1073cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------------+------+-------------+-------+------------------------+\n",
      "|     Name| Age|Years_Experience|Height|Location_City|Sallary|Experience_after_2_years|\n",
      "+---------+----+----------------+------+-------------+-------+------------------------+\n",
      "|     Emma|  47|               4|  1.68|      Chicago| 148190|                       6|\n",
      "|     Noah|  73|               1|  1.55|     New York| 225073|                       3|\n",
      "|   Olivia|  32|               1|  1.66|  Los Angeles| 115666|                       3|\n",
      "|     Liam|  75|              10|  1.58|San Francisco| 103567|                      12|\n",
      "|      Ava|   9|               1|  1.96|      Chicago| 149350|                       3|\n",
      "| Isabella|  78|              10|  1.79|     New York| 109479|                      12|\n",
      "|   Sophia|  80|               7|  1.95|  Los Angeles|  97866|                       9|\n",
      "|      Mia|  62|            null|  1.79|San Francisco| 154475|                    null|\n",
      "|Charlotte|  61|              10|  1.73|      Chicago| 199876|                      12|\n",
      "|   Amelia|  58|               2|   1.6|     New York| 214669|                       4|\n",
      "|   Harper|  74|               1|  1.79|  Los Angeles| 179705|                       3|\n",
      "|   Evelyn|  53|               6|  1.97|San Francisco| 171232|                       8|\n",
      "|  Abigail|  38|               2|  1.59|      Chicago|   null|                       4|\n",
      "|    Emily|  20|               9|  1.89|     New York| 144910|                      11|\n",
      "|Elizabeth|  22|              10|  1.69|  Los Angeles| 224057|                      12|\n",
      "|     Mila|  78|              10|  1.64|San Francisco| 139386|                      12|\n",
      "|     Ella|  29|               5|  1.95|      Chicago| 160033|                       7|\n",
      "|    Avery|null|              10|  1.97|     New York|  94983|                      12|\n",
      "|    Sofia|  56|               7|  2.02|  Los Angeles| 124729|                       9|\n",
      "|   Camila|  66|               4|  1.98|San Francisco| 188518|                       6|\n",
      "+---------+----+----------------+------+-------------+-------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e00a74d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns\n",
    "df_pyspark = df_pyspark.drop('Experience_after_2_years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8de6089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------------+------+-------------+-------+\n",
      "|     Name| Age|Years_Experience|Height|Location_City|Sallary|\n",
      "+---------+----+----------------+------+-------------+-------+\n",
      "|     Emma|  47|               4|  1.68|      Chicago| 148190|\n",
      "|     Noah|  73|               1|  1.55|     New York| 225073|\n",
      "|   Olivia|  32|               1|  1.66|  Los Angeles| 115666|\n",
      "|     Liam|  75|              10|  1.58|San Francisco| 103567|\n",
      "|      Ava|   9|               1|  1.96|      Chicago| 149350|\n",
      "| Isabella|  78|              10|  1.79|     New York| 109479|\n",
      "|   Sophia|  80|               7|  1.95|  Los Angeles|  97866|\n",
      "|      Mia|  62|            null|  1.79|San Francisco| 154475|\n",
      "|Charlotte|  61|              10|  1.73|      Chicago| 199876|\n",
      "|   Amelia|  58|               2|   1.6|     New York| 214669|\n",
      "|   Harper|  74|               1|  1.79|  Los Angeles| 179705|\n",
      "|   Evelyn|  53|               6|  1.97|San Francisco| 171232|\n",
      "|  Abigail|  38|               2|  1.59|      Chicago|   null|\n",
      "|    Emily|  20|               9|  1.89|     New York| 144910|\n",
      "|Elizabeth|  22|              10|  1.69|  Los Angeles| 224057|\n",
      "|     Mila|  78|              10|  1.64|San Francisco| 139386|\n",
      "|     Ella|  29|               5|  1.95|      Chicago| 160033|\n",
      "|    Avery|null|              10|  1.97|     New York|  94983|\n",
      "|    Sofia|  56|               7|  2.02|  Los Angeles| 124729|\n",
      "|   Camila|  66|               4|  1.98|San Francisco| 188518|\n",
      "+---------+----+----------------+------+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "982d7582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------------+------+-------------+-------+\n",
      "| New_Name| Age|Years_Experience|Height|Location_City|Sallary|\n",
      "+---------+----+----------------+------+-------------+-------+\n",
      "|     Emma|  47|               4|  1.68|      Chicago| 148190|\n",
      "|     Noah|  73|               1|  1.55|     New York| 225073|\n",
      "|   Olivia|  32|               1|  1.66|  Los Angeles| 115666|\n",
      "|     Liam|  75|              10|  1.58|San Francisco| 103567|\n",
      "|      Ava|   9|               1|  1.96|      Chicago| 149350|\n",
      "| Isabella|  78|              10|  1.79|     New York| 109479|\n",
      "|   Sophia|  80|               7|  1.95|  Los Angeles|  97866|\n",
      "|      Mia|  62|            null|  1.79|San Francisco| 154475|\n",
      "|Charlotte|  61|              10|  1.73|      Chicago| 199876|\n",
      "|   Amelia|  58|               2|   1.6|     New York| 214669|\n",
      "|   Harper|  74|               1|  1.79|  Los Angeles| 179705|\n",
      "|   Evelyn|  53|               6|  1.97|San Francisco| 171232|\n",
      "|  Abigail|  38|               2|  1.59|      Chicago|   null|\n",
      "|    Emily|  20|               9|  1.89|     New York| 144910|\n",
      "|Elizabeth|  22|              10|  1.69|  Los Angeles| 224057|\n",
      "|     Mila|  78|              10|  1.64|San Francisco| 139386|\n",
      "|     Ella|  29|               5|  1.95|      Chicago| 160033|\n",
      "|    Avery|null|              10|  1.97|     New York|  94983|\n",
      "|    Sofia|  56|               7|  2.02|  Los Angeles| 124729|\n",
      "|   Camila|  66|               4|  1.98|San Francisco| 188518|\n",
      "+---------+----+----------------+------+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rename Columns. I'm not s\n",
    "df_pyspark.withColumnRenamed('Name','New_Name').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba2b6ef",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "* Drop Columns\n",
    "* Drop Rows\n",
    "* Parameters in dropping functionality\n",
    "* Handle missing values by mean, median , and mode. Imputer function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499547e3",
   "metadata": {},
   "source": [
    "### Drop Columns and Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72ede839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+------+-------------+-------+\n",
      "|     Name|Years_Experience|Height|Location_City|Sallary|\n",
      "+---------+----------------+------+-------------+-------+\n",
      "|     Emma|               4|  1.68|      Chicago| 148190|\n",
      "|     Noah|               1|  1.55|     New York| 225073|\n",
      "|   Olivia|               1|  1.66|  Los Angeles| 115666|\n",
      "|     Liam|              10|  1.58|San Francisco| 103567|\n",
      "|      Ava|               1|  1.96|      Chicago| 149350|\n",
      "| Isabella|              10|  1.79|     New York| 109479|\n",
      "|   Sophia|               7|  1.95|  Los Angeles|  97866|\n",
      "|      Mia|            null|  1.79|San Francisco| 154475|\n",
      "|Charlotte|              10|  1.73|      Chicago| 199876|\n",
      "|   Amelia|               2|   1.6|     New York| 214669|\n",
      "|   Harper|               1|  1.79|  Los Angeles| 179705|\n",
      "|   Evelyn|               6|  1.97|San Francisco| 171232|\n",
      "|  Abigail|               2|  1.59|      Chicago|   null|\n",
      "|    Emily|               9|  1.89|     New York| 144910|\n",
      "|Elizabeth|              10|  1.69|  Los Angeles| 224057|\n",
      "|     Mila|              10|  1.64|San Francisco| 139386|\n",
      "|     Ella|               5|  1.95|      Chicago| 160033|\n",
      "|    Avery|              10|  1.97|     New York|  94983|\n",
      "|    Sofia|               7|  2.02|  Los Angeles| 124729|\n",
      "|   Camila|               4|  1.98|San Francisco| 188518|\n",
      "+---------+----------------+------+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Drop age column without saving to new varable\n",
    "df_pyspark.drop('Age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e6563ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------------+------+-------------+-------+\n",
      "|     Name|Age|Years_Experience|Height|Location_City|Sallary|\n",
      "+---------+---+----------------+------+-------------+-------+\n",
      "|     Emma| 47|               4|  1.68|      Chicago| 148190|\n",
      "|     Noah| 73|               1|  1.55|     New York| 225073|\n",
      "|   Olivia| 32|               1|  1.66|  Los Angeles| 115666|\n",
      "|     Liam| 75|              10|  1.58|San Francisco| 103567|\n",
      "|      Ava|  9|               1|  1.96|      Chicago| 149350|\n",
      "| Isabella| 78|              10|  1.79|     New York| 109479|\n",
      "|   Sophia| 80|               7|  1.95|  Los Angeles|  97866|\n",
      "|Charlotte| 61|              10|  1.73|      Chicago| 199876|\n",
      "|   Amelia| 58|               2|   1.6|     New York| 214669|\n",
      "|   Harper| 74|               1|  1.79|  Los Angeles| 179705|\n",
      "|   Evelyn| 53|               6|  1.97|San Francisco| 171232|\n",
      "|    Emily| 20|               9|  1.89|     New York| 144910|\n",
      "|Elizabeth| 22|              10|  1.69|  Los Angeles| 224057|\n",
      "|     Mila| 78|              10|  1.64|San Francisco| 139386|\n",
      "|     Ella| 29|               5|  1.95|      Chicago| 160033|\n",
      "|    Sofia| 56|               7|  2.02|  Los Angeles| 124729|\n",
      "|   Camila| 66|               4|  1.98|San Francisco| 188518|\n",
      "|     Aria| 78|               4|  1.79|      Chicago| 217043|\n",
      "| Scarlett| 67|               8|   2.0|     New York| 194911|\n",
      "| Victoria| 67|               1|  1.85|  Los Angeles|  92620|\n",
      "+---------+---+----------------+------+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop rows based on null value\n",
    "df_pyspark_dropped_rows = df_pyspark.na.drop()\n",
    "df_pyspark_dropped_rows.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0113089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------------+------+-------------+-------+\n",
      "|     Name|Age|Years_Experience|Height|Location_City|Sallary|\n",
      "+---------+---+----------------+------+-------------+-------+\n",
      "|     Emma| 47|               4|  1.68|      Chicago| 148190|\n",
      "|     Noah| 73|               1|  1.55|     New York| 225073|\n",
      "|   Olivia| 32|               1|  1.66|  Los Angeles| 115666|\n",
      "|     Liam| 75|              10|  1.58|San Francisco| 103567|\n",
      "|      Ava|  9|               1|  1.96|      Chicago| 149350|\n",
      "| Isabella| 78|              10|  1.79|     New York| 109479|\n",
      "|   Sophia| 80|               7|  1.95|  Los Angeles|  97866|\n",
      "|Charlotte| 61|              10|  1.73|      Chicago| 199876|\n",
      "|   Amelia| 58|               2|   1.6|     New York| 214669|\n",
      "|   Harper| 74|               1|  1.79|  Los Angeles| 179705|\n",
      "|   Evelyn| 53|               6|  1.97|San Francisco| 171232|\n",
      "|    Emily| 20|               9|  1.89|     New York| 144910|\n",
      "|Elizabeth| 22|              10|  1.69|  Los Angeles| 224057|\n",
      "|     Mila| 78|              10|  1.64|San Francisco| 139386|\n",
      "|     Ella| 29|               5|  1.95|      Chicago| 160033|\n",
      "|    Sofia| 56|               7|  2.02|  Los Angeles| 124729|\n",
      "|   Camila| 66|               4|  1.98|San Francisco| 188518|\n",
      "|     Aria| 78|               4|  1.79|      Chicago| 217043|\n",
      "| Scarlett| 67|               8|   2.0|     New York| 194911|\n",
      "| Victoria| 67|               1|  1.85|  Los Angeles|  92620|\n",
      "+---------+---+----------------+------+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#How parameter = all, only drops row if entire row has nulls\n",
    "#How parameter = any, drop row if any colum has a null\n",
    "df_pyspark.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb0b1bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------------+------+-------------+-------+\n",
      "|     Name| Age|Years_Experience|Height|Location_City|Sallary|\n",
      "+---------+----+----------------+------+-------------+-------+\n",
      "|     Emma|  47|               4|  1.68|      Chicago| 148190|\n",
      "|     Noah|  73|               1|  1.55|     New York| 225073|\n",
      "|   Olivia|  32|               1|  1.66|  Los Angeles| 115666|\n",
      "|     Liam|  75|              10|  1.58|San Francisco| 103567|\n",
      "|      Ava|   9|               1|  1.96|      Chicago| 149350|\n",
      "| Isabella|  78|              10|  1.79|     New York| 109479|\n",
      "|   Sophia|  80|               7|  1.95|  Los Angeles|  97866|\n",
      "|      Mia|  62|            null|  1.79|San Francisco| 154475|\n",
      "|Charlotte|  61|              10|  1.73|      Chicago| 199876|\n",
      "|   Amelia|  58|               2|   1.6|     New York| 214669|\n",
      "|   Harper|  74|               1|  1.79|  Los Angeles| 179705|\n",
      "|   Evelyn|  53|               6|  1.97|San Francisco| 171232|\n",
      "|  Abigail|  38|               2|  1.59|      Chicago|   null|\n",
      "|    Emily|  20|               9|  1.89|     New York| 144910|\n",
      "|Elizabeth|  22|              10|  1.69|  Los Angeles| 224057|\n",
      "|     Mila|  78|              10|  1.64|San Francisco| 139386|\n",
      "|     Ella|  29|               5|  1.95|      Chicago| 160033|\n",
      "|    Avery|null|              10|  1.97|     New York|  94983|\n",
      "|    Sofia|  56|               7|  2.02|  Los Angeles| 124729|\n",
      "|   Camila|  66|               4|  1.98|San Francisco| 188518|\n",
      "+---------+----+----------------+------+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Threshold - sets how many null values must be present in row before deleting\n",
    "df_pyspark.na.drop(how='any', thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd76164a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------------+------+-------------+-------+\n",
      "|     Name| Age|Years_Experience|Height|Location_City|Sallary|\n",
      "+---------+----+----------------+------+-------------+-------+\n",
      "|     Emma|  47|               4|  1.68|      Chicago| 148190|\n",
      "|     Noah|  73|               1|  1.55|     New York| 225073|\n",
      "|   Olivia|  32|               1|  1.66|  Los Angeles| 115666|\n",
      "|     Liam|  75|              10|  1.58|San Francisco| 103567|\n",
      "|      Ava|   9|               1|  1.96|      Chicago| 149350|\n",
      "| Isabella|  78|              10|  1.79|     New York| 109479|\n",
      "|   Sophia|  80|               7|  1.95|  Los Angeles|  97866|\n",
      "|      Mia|  62|            null|  1.79|San Francisco| 154475|\n",
      "|Charlotte|  61|              10|  1.73|      Chicago| 199876|\n",
      "|   Amelia|  58|               2|   1.6|     New York| 214669|\n",
      "|   Harper|  74|               1|  1.79|  Los Angeles| 179705|\n",
      "|   Evelyn|  53|               6|  1.97|San Francisco| 171232|\n",
      "|    Emily|  20|               9|  1.89|     New York| 144910|\n",
      "|Elizabeth|  22|              10|  1.69|  Los Angeles| 224057|\n",
      "|     Mila|  78|              10|  1.64|San Francisco| 139386|\n",
      "|     Ella|  29|               5|  1.95|      Chicago| 160033|\n",
      "|    Avery|null|              10|  1.97|     New York|  94983|\n",
      "|    Sofia|  56|               7|  2.02|  Los Angeles| 124729|\n",
      "|   Camila|  66|               4|  1.98|San Francisco| 188518|\n",
      "|     Aria|  78|               4|  1.79|      Chicago| 217043|\n",
      "+---------+----+----------------+------+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Subset - specify what columns you want to drop nulls from. Let's try dropping only in the Sallary column\n",
    "df_pyspark.na.drop(how='any', subset=['Sallary']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372f5d00",
   "metadata": {},
   "source": [
    "### Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "911ac65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "#create imputer with mean fill strategy. Specify input and output columns\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['Age', 'Sallary', 'Years_Experience'],\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['Age', 'Sallary', 'Years_Experience']]\n",
    "    ).setStrategy(\"mean\")\n",
    "#Can replace mean with median or mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7aeb106c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------------+------+-------------+-------+-----------+---------------+------------------------+\n",
      "|     Name| Age|Years_Experience|Height|Location_City|Sallary|Age_imputed|Sallary_imputed|Years_Experience_imputed|\n",
      "+---------+----+----------------+------+-------------+-------+-----------+---------------+------------------------+\n",
      "|     Emma|  47|               4|  1.68|      Chicago| 148190|         47|         148190|                       4|\n",
      "|     Noah|  73|               1|  1.55|     New York| 225073|         73|         225073|                       1|\n",
      "|   Olivia|  32|               1|  1.66|  Los Angeles| 115666|         32|         115666|                       1|\n",
      "|     Liam|  75|              10|  1.58|San Francisco| 103567|         75|         103567|                      10|\n",
      "|      Ava|   9|               1|  1.96|      Chicago| 149350|          9|         149350|                       1|\n",
      "| Isabella|  78|              10|  1.79|     New York| 109479|         78|         109479|                      10|\n",
      "|   Sophia|  80|               7|  1.95|  Los Angeles|  97866|         80|          97866|                       7|\n",
      "|      Mia|  62|            null|  1.79|San Francisco| 154475|         62|         154475|                       5|\n",
      "|Charlotte|  61|              10|  1.73|      Chicago| 199876|         61|         199876|                      10|\n",
      "|   Amelia|  58|               2|   1.6|     New York| 214669|         58|         214669|                       2|\n",
      "|   Harper|  74|               1|  1.79|  Los Angeles| 179705|         74|         179705|                       1|\n",
      "|   Evelyn|  53|               6|  1.97|San Francisco| 171232|         53|         171232|                       6|\n",
      "|  Abigail|  38|               2|  1.59|      Chicago|   null|         38|         160968|                       2|\n",
      "|    Emily|  20|               9|  1.89|     New York| 144910|         20|         144910|                       9|\n",
      "|Elizabeth|  22|              10|  1.69|  Los Angeles| 224057|         22|         224057|                      10|\n",
      "|     Mila|  78|              10|  1.64|San Francisco| 139386|         78|         139386|                      10|\n",
      "|     Ella|  29|               5|  1.95|      Chicago| 160033|         29|         160033|                       5|\n",
      "|    Avery|null|              10|  1.97|     New York|  94983|         49|          94983|                      10|\n",
      "|    Sofia|  56|               7|  2.02|  Los Angeles| 124729|         56|         124729|                       7|\n",
      "|   Camila|  66|               4|  1.98|San Francisco| 188518|         66|         188518|                       4|\n",
      "|     Aria|  78|               4|  1.79|      Chicago| 217043|         78|         217043|                       4|\n",
      "| Scarlett|  67|               8|   2.0|     New York| 194911|         67|         194911|                       8|\n",
      "| Victoria|  67|               1|  1.85|  Los Angeles|  92620|         67|          92620|                       1|\n",
      "|  Madison|  23|               3|  1.87|San Francisco| 195767|         23|         195767|                       3|\n",
      "|     Luna|  37|               6|  1.55|      Chicago| 216338|         37|         216338|                       6|\n",
      "|    Grace|  22|               8|   1.8|     New York| 212176|         22|         212176|                       8|\n",
      "|    Chloe|  22|            null|  1.92|  Los Angeles| 146957|         22|         146957|                       5|\n",
      "| Penelope|  58|               9|  1.72|San Francisco| 168719|         58|         168719|                       9|\n",
      "|    Layla|  36|               9|  2.01|      Chicago| 141444|         36|         141444|                       9|\n",
      "|    Riley|  60|               3|   2.0|     New York| 215036|         60|         215036|                       3|\n",
      "|     Zoey|  79|               1|  1.59|  Los Angeles|  80860|         79|          80860|                       1|\n",
      "|     Nora|  61|               2|  1.82|San Francisco| 108105|         61|         108105|                       2|\n",
      "|     Lily|  35|               3|   1.9|      Chicago|   null|         35|         160968|                       3|\n",
      "|  Eleanor|  37|               9|  1.79|     New York| 139093|         37|         139093|                       9|\n",
      "|   Hannah|  56|               2|  1.56|  Los Angeles| 222320|         56|         222320|                       2|\n",
      "|  Lillian|  73|               3|  1.61|San Francisco| 161724|         73|         161724|                       3|\n",
      "|  Addison|  13|               6|  2.02|      Chicago| 174984|         13|         174984|                       6|\n",
      "|   Aubrey|  52|               1|  2.01|     New York| 215938|         52|         215938|                       1|\n",
      "|    Ellie|  29|               5|  1.63|  Los Angeles| 120808|         29|         120808|                       5|\n",
      "|   Stella|  26|               9|  1.62|San Francisco| 123158|         26|         123158|                       9|\n",
      "|  Natalie|  14|               7|  1.92|      Chicago| 218458|         14|         218458|                       7|\n",
      "|      Zoe|  65|              10|  1.68|     New York| 212527|         65|         212527|                      10|\n",
      "|     Leah|null|               7|  1.84|  Los Angeles| 159327|         49|         159327|                       7|\n",
      "|    Hazel|  34|               4|  1.62|San Francisco| 131026|         34|         131026|                       4|\n",
      "|   Violet|  58|               3|  1.55|      Chicago| 102573|         58|         102573|                       3|\n",
      "|   Aurora|  66|              10|  1.55|     New York| 197903|         66|         197903|                      10|\n",
      "| Savannah|  49|            null|  1.93|  Los Angeles| 216618|         49|         216618|                       5|\n",
      "|   Audrey|  35|               2|  1.99|San Francisco| 206294|         35|         206294|                       2|\n",
      "| Brooklyn|  45|               7|  1.55|      Chicago| 109875|         45|         109875|                       7|\n",
      "|    Bella|  79|               7|  1.63|     New York|  78133|         79|          78133|                       7|\n",
      "+---------+----+----------------+------+-------------+-------+-----------+---------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fill with mean\n",
    "df_pyspark_fill_mean = imputer.fit(df_pyspark).transform(df_pyspark)\n",
    "df_pyspark_fill_mean.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823d4acf",
   "metadata": {},
   "source": [
    "Let's drop the original columns to clean up the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75ed487a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-------------+-----------+---------------+------------------------+\n",
      "|     Name|Height|Location_City|Age_imputed|Sallary_imputed|Years_Experience_imputed|\n",
      "+---------+------+-------------+-----------+---------------+------------------------+\n",
      "|     Emma|  1.68|      Chicago|         47|         148190|                       4|\n",
      "|     Noah|  1.55|     New York|         73|         225073|                       1|\n",
      "|   Olivia|  1.66|  Los Angeles|         32|         115666|                       1|\n",
      "|     Liam|  1.58|San Francisco|         75|         103567|                      10|\n",
      "|      Ava|  1.96|      Chicago|          9|         149350|                       1|\n",
      "| Isabella|  1.79|     New York|         78|         109479|                      10|\n",
      "|   Sophia|  1.95|  Los Angeles|         80|          97866|                       7|\n",
      "|      Mia|  1.79|San Francisco|         62|         154475|                       5|\n",
      "|Charlotte|  1.73|      Chicago|         61|         199876|                      10|\n",
      "|   Amelia|   1.6|     New York|         58|         214669|                       2|\n",
      "|   Harper|  1.79|  Los Angeles|         74|         179705|                       1|\n",
      "|   Evelyn|  1.97|San Francisco|         53|         171232|                       6|\n",
      "|  Abigail|  1.59|      Chicago|         38|         160968|                       2|\n",
      "|    Emily|  1.89|     New York|         20|         144910|                       9|\n",
      "|Elizabeth|  1.69|  Los Angeles|         22|         224057|                      10|\n",
      "|     Mila|  1.64|San Francisco|         78|         139386|                      10|\n",
      "|     Ella|  1.95|      Chicago|         29|         160033|                       5|\n",
      "|    Avery|  1.97|     New York|         49|          94983|                      10|\n",
      "|    Sofia|  2.02|  Los Angeles|         56|         124729|                       7|\n",
      "|   Camila|  1.98|San Francisco|         66|         188518|                       4|\n",
      "+---------+------+-------------+-----------+---------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark_fill_mean = df_pyspark_fill_mean.drop('Age', 'Sallary', 'Years_Experience')\n",
    "df_pyspark_fill_mean.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc985e7d",
   "metadata": {},
   "source": [
    "## Filter Operations\n",
    "This is important for data preprocessiong, if you want to retreive data based on a set of conditions.\n",
    "* filter operations\n",
    "* &, |, ==\n",
    "* ~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cefebe3",
   "metadata": {},
   "source": [
    "Let's find the salary of people equal or less than $120,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50005d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------------+-----------+---------------+------------------------+\n",
      "|    Name|Height|Location_City|Age_imputed|Sallary_imputed|Years_Experience_imputed|\n",
      "+--------+------+-------------+-----------+---------------+------------------------+\n",
      "|  Olivia|  1.66|  Los Angeles|         32|         115666|                       1|\n",
      "|    Liam|  1.58|San Francisco|         75|         103567|                      10|\n",
      "|Isabella|  1.79|     New York|         78|         109479|                      10|\n",
      "|  Sophia|  1.95|  Los Angeles|         80|          97866|                       7|\n",
      "|   Avery|  1.97|     New York|         49|          94983|                      10|\n",
      "|Victoria|  1.85|  Los Angeles|         67|          92620|                       1|\n",
      "|    Zoey|  1.59|  Los Angeles|         79|          80860|                       1|\n",
      "|    Nora|  1.82|San Francisco|         61|         108105|                       2|\n",
      "|  Violet|  1.55|      Chicago|         58|         102573|                       3|\n",
      "|Brooklyn|  1.55|      Chicago|         45|         109875|                       7|\n",
      "|   Bella|  1.63|     New York|         79|          78133|                       7|\n",
      "+--------+------+-------------+-----------+---------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark_fill_mean.filter(\"Sallary_imputed <= 120000\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb003d3",
   "metadata": {},
   "source": [
    "Let's select the name and age from this subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e482d31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|    Name|Age_imputed|\n",
      "+--------+-----------+\n",
      "|  Olivia|         32|\n",
      "|    Liam|         75|\n",
      "|Isabella|         78|\n",
      "|  Sophia|         80|\n",
      "|   Avery|         49|\n",
      "|Victoria|         67|\n",
      "|    Zoey|         79|\n",
      "|    Nora|         61|\n",
      "|  Violet|         58|\n",
      "|Brooklyn|         45|\n",
      "|   Bella|         79|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark_fill_mean.filter(\"Sallary_imputed <= 120000\").select(\"Name\", \"Age_imputed\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556b25b",
   "metadata": {},
   "source": [
    "Let's filter for two conditions using and operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21b6b182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------------+-----------+---------------+------------------------+\n",
      "|    Name|Height|Location_City|Age_imputed|Sallary_imputed|Years_Experience_imputed|\n",
      "+--------+------+-------------+-----------+---------------+------------------------+\n",
      "|    Emma|  1.68|      Chicago|         47|         148190|                       4|\n",
      "|  Olivia|  1.66|  Los Angeles|         32|         115666|                       1|\n",
      "|    Liam|  1.58|San Francisco|         75|         103567|                      10|\n",
      "|     Ava|  1.96|      Chicago|          9|         149350|                       1|\n",
      "|Isabella|  1.79|     New York|         78|         109479|                      10|\n",
      "|   Emily|  1.89|     New York|         20|         144910|                       9|\n",
      "|    Mila|  1.64|San Francisco|         78|         139386|                      10|\n",
      "|   Sofia|  2.02|  Los Angeles|         56|         124729|                       7|\n",
      "|   Chloe|  1.92|  Los Angeles|         22|         146957|                       5|\n",
      "|   Layla|  2.01|      Chicago|         36|         141444|                       9|\n",
      "|    Nora|  1.82|San Francisco|         61|         108105|                       2|\n",
      "| Eleanor|  1.79|     New York|         37|         139093|                       9|\n",
      "|   Ellie|  1.63|  Los Angeles|         29|         120808|                       5|\n",
      "|  Stella|  1.62|San Francisco|         26|         123158|                       9|\n",
      "|   Hazel|  1.62|San Francisco|         34|         131026|                       4|\n",
      "|  Violet|  1.55|      Chicago|         58|         102573|                       3|\n",
      "|Brooklyn|  1.55|      Chicago|         45|         109875|                       7|\n",
      "+--------+------+-------------+-----------+---------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark_fill_mean.filter((df_pyspark_fill_mean['Sallary_imputed'] <= 150000) & \n",
    "                            (df_pyspark_fill_mean['Sallary_imputed'] > 100000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8dbf7e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-------------+-----------+---------------+------------------------+\n",
      "|     Name|Height|Location_City|Age_imputed|Sallary_imputed|Years_Experience_imputed|\n",
      "+---------+------+-------------+-----------+---------------+------------------------+\n",
      "|     Emma|  1.68|      Chicago|         47|         148190|                       4|\n",
      "|     Noah|  1.55|     New York|         73|         225073|                       1|\n",
      "|   Olivia|  1.66|  Los Angeles|         32|         115666|                       1|\n",
      "|     Liam|  1.58|San Francisco|         75|         103567|                      10|\n",
      "|      Ava|  1.96|      Chicago|          9|         149350|                       1|\n",
      "| Isabella|  1.79|     New York|         78|         109479|                      10|\n",
      "|   Sophia|  1.95|  Los Angeles|         80|          97866|                       7|\n",
      "|      Mia|  1.79|San Francisco|         62|         154475|                       5|\n",
      "|Charlotte|  1.73|      Chicago|         61|         199876|                      10|\n",
      "|   Amelia|   1.6|     New York|         58|         214669|                       2|\n",
      "|   Harper|  1.79|  Los Angeles|         74|         179705|                       1|\n",
      "|   Evelyn|  1.97|San Francisco|         53|         171232|                       6|\n",
      "|  Abigail|  1.59|      Chicago|         38|         160968|                       2|\n",
      "|    Emily|  1.89|     New York|         20|         144910|                       9|\n",
      "|Elizabeth|  1.69|  Los Angeles|         22|         224057|                      10|\n",
      "|     Mila|  1.64|San Francisco|         78|         139386|                      10|\n",
      "|     Ella|  1.95|      Chicago|         29|         160033|                       5|\n",
      "|    Avery|  1.97|     New York|         49|          94983|                      10|\n",
      "|    Sofia|  2.02|  Los Angeles|         56|         124729|                       7|\n",
      "|   Camila|  1.98|San Francisco|         66|         188518|                       4|\n",
      "+---------+------+-------------+-----------+---------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filter using or operator\n",
    "df_pyspark_fill_mean.filter((df_pyspark_fill_mean['Sallary_imputed'] <= 150000) | \n",
    "                            (df_pyspark_fill_mean['Sallary_imputed'] > 100000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50dac1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-------------+-----------+---------------+------------------------+\n",
      "|     Name|Height|Location_City|Age_imputed|Sallary_imputed|Years_Experience_imputed|\n",
      "+---------+------+-------------+-----------+---------------+------------------------+\n",
      "|Charlotte|  1.73|      Chicago|         61|         199876|                      10|\n",
      "|  Abigail|  1.59|      Chicago|         38|         160968|                       2|\n",
      "|     Ella|  1.95|      Chicago|         29|         160033|                       5|\n",
      "|     Aria|  1.79|      Chicago|         78|         217043|                       4|\n",
      "|     Luna|  1.55|      Chicago|         37|         216338|                       6|\n",
      "|     Lily|   1.9|      Chicago|         35|         160968|                       3|\n",
      "|  Addison|  2.02|      Chicago|         13|         174984|                       6|\n",
      "|  Natalie|  1.92|      Chicago|         14|         218458|                       7|\n",
      "+---------+------+-------------+-----------+---------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#People making more than 150,000 in Chicago\n",
    "df_pyspark_fill_mean.filter((df_pyspark_fill_mean['Sallary_imputed'] > 150000) & \n",
    "                            (df_pyspark_fill_mean['Location_City'] == 'Chicago')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6bed818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------------+-----------+---------------+------------------------+\n",
      "|    Name|Height|Location_City|Age_imputed|Sallary_imputed|Years_Experience_imputed|\n",
      "+--------+------+-------------+-----------+---------------+------------------------+\n",
      "|    Emma|  1.68|      Chicago|         47|         148190|                       4|\n",
      "|  Olivia|  1.66|  Los Angeles|         32|         115666|                       1|\n",
      "|    Liam|  1.58|San Francisco|         75|         103567|                      10|\n",
      "|     Ava|  1.96|      Chicago|          9|         149350|                       1|\n",
      "|Isabella|  1.79|     New York|         78|         109479|                      10|\n",
      "|  Sophia|  1.95|  Los Angeles|         80|          97866|                       7|\n",
      "|   Emily|  1.89|     New York|         20|         144910|                       9|\n",
      "|    Mila|  1.64|San Francisco|         78|         139386|                      10|\n",
      "|   Avery|  1.97|     New York|         49|          94983|                      10|\n",
      "|   Sofia|  2.02|  Los Angeles|         56|         124729|                       7|\n",
      "|Victoria|  1.85|  Los Angeles|         67|          92620|                       1|\n",
      "|   Chloe|  1.92|  Los Angeles|         22|         146957|                       5|\n",
      "|   Layla|  2.01|      Chicago|         36|         141444|                       9|\n",
      "|    Zoey|  1.59|  Los Angeles|         79|          80860|                       1|\n",
      "|    Nora|  1.82|San Francisco|         61|         108105|                       2|\n",
      "| Eleanor|  1.79|     New York|         37|         139093|                       9|\n",
      "|   Ellie|  1.63|  Los Angeles|         29|         120808|                       5|\n",
      "|  Stella|  1.62|San Francisco|         26|         123158|                       9|\n",
      "|   Hazel|  1.62|San Francisco|         34|         131026|                       4|\n",
      "|  Violet|  1.55|      Chicago|         58|         102573|                       3|\n",
      "|Brooklyn|  1.55|      Chicago|         45|         109875|                       7|\n",
      "|   Bella|  1.63|     New York|         79|          78133|                       7|\n",
      "+--------+------+-------------+-----------+---------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Try filtering with 'not condition'. People who at NOT making more than 150,000\n",
    "df_pyspark_fill_mean.filter(~(df_pyspark_fill_mean['Sallary_imputed'] > 150000)).show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2673d132",
   "metadata": {},
   "source": [
    "## GroupBy and Agregate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e70e7d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+------------+-------+\n",
      "|     Name| Age|  Department|Sallary|\n",
      "+---------+----+------------+-------+\n",
      "|     Emma|  29|         IoT| 113938|\n",
      "|     Noah|  47|Data Science| 193905|\n",
      "|   Olivia|  35|          IT| 125014|\n",
      "|     Liam|   9|     Support| 134964|\n",
      "|      Ava|  64|     Backend| 157453|\n",
      "| Isabella|  24|    Frontend|  94749|\n",
      "|   Sophia|  39|         IoT|  82228|\n",
      "|      Mia|  16|Data Science| 171357|\n",
      "|Charlotte|  68|          IT| 124426|\n",
      "|   Amelia|  38|     Support| 127667|\n",
      "|   Harper|  63|     Backend|  98063|\n",
      "|   Evelyn|  43|    Frontend| 119494|\n",
      "|  Abigail|  66|         IoT|   null|\n",
      "|    Emily|  73|Data Science| 128182|\n",
      "|Elizabeth|  60|          IT| 168372|\n",
      "|     Mila|  14|     Support| 164825|\n",
      "|     Ella|  46|     Backend| 179306|\n",
      "|    Avery|null|    Frontend| 131310|\n",
      "|    Sofia|  80|         IoT| 220873|\n",
      "|   Camila|  10|Data Science|  94252|\n",
      "+---------+----+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load new dataset\n",
    "df_pyspark = spark.read.option('header', 'true').csv('department_data.csv', inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913051d5",
   "metadata": {},
   "source": [
    "### GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "86890dba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|  Department|sum(Sallary)|\n",
      "+------------+------------+\n",
      "|    Frontend|     1131719|\n",
      "|         IoT|     1276485|\n",
      "|          IT|      878871|\n",
      "|     Support|     1105691|\n",
      "|     Backend|     1229310|\n",
      "|Data Science|     1279569|\n",
      "+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#What department cost the most (has highest total salary). Drop the summed Age column\n",
    "df_pyspark.groupBy('Department').sum().drop('sum(Age)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "28791f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|  Department|      avg(Sallary)|\n",
      "+------------+------------------+\n",
      "|    Frontend|        141464.875|\n",
      "|         IoT|        159560.625|\n",
      "|          IT|          125553.0|\n",
      "|     Support|        138211.375|\n",
      "|     Backend|         153663.75|\n",
      "|Data Science|142174.33333333334|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#What department has the highest mean salary?\n",
    "df_pyspark.groupBy('Department').mean().drop('avg(Age)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "505ba35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|  Department|count|\n",
      "+------------+-----+\n",
      "|    Frontend|    8|\n",
      "|         IoT|    9|\n",
      "|          IT|    8|\n",
      "|     Support|    8|\n",
      "|     Backend|    8|\n",
      "|Data Science|    9|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#How many employees work in each department\n",
    "df_pyspark.groupBy('Department').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fb60387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|sum(Sallary)|\n",
      "+------------+\n",
      "|     6901645|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#What's the total salary\n",
    "df_pyspark.agg({'Sallary':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73fb2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
